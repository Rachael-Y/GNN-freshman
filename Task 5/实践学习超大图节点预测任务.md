实践学习超大图节点预测任务

https://github.com/datawhalechina/team-learning-nlp/blob/master/GNN/Markdown%E7%89%88%E6%9C%AC/5-%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%8A%82%E7%82%B9%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0.md


PyG中GCNConv 模块说明
GCNConv构造函数接口：

GCNConv(in_channels: int, out_channels: int, improved: bool = False, cached: bool = False, add_self_loops: bool = True, normalize: bool = True, bias: bool = True, **kwargs)
其中：

in_channels ：输入数据维度；
out_channels ：输出数据维度；
improved ：如果为true，$\mathbf{\hat{A}} = \mathbf{A} + 2\mathbf{I}$，其目的在于增强中心节点自身信息；
cached ：是否存储$\mathbf{\hat{D}}^{-1/2} \mathbf{\hat{A}} \mathbf{\hat{D}}^{-1/2}$的计算结果以便后续使用，这个参数只应在归纳学习（transductive learning）的场景中设置为true（归纳学习可以简单理解为在训练、验证、测试、推理（inference）四个阶段都只使用一个数据集）；
add_self_loops ：是否在邻接矩阵中增加自环边；
normalize ：是否添加自环边并在运行中计算对称归一化系数；
bias ：是否包含偏置项。
详细内容请大家参阅GCNConv官方文档。

GCN图神经网络的构造
将上面例子中的torch.nn.Linear替换成torch_geometric.nn.GCNConv，我们就可以得到一个GCN图神经网络，如下方代码所示：

from torch_geometric.nn import GCNConv

class GCN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super(GCN, self).__init__()
        torch.manual_seed(12345)
        self.conv1 = GCNConv(dataset.num_features, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv2(x, edge_index)
        return x

model = GCN(hidden_channels=16)
print(model)
可视化由未经训练的GCN图神经网络生成的节点表征
代码如下所示：

model = GCN(hidden_channels=16)
model.eval()

out = model(data.x, data.edge_index)
visualize(out, color=data.y)
经过visualize函数的处理，7维特征的节点被映射到2维的平面上。我们会惊喜地看到“同类节点群聚”的现象。

image-20210526214252415

GCN图神经网络的训练
通过下方的代码我们可实现GCN图神经网络的训练：

model = GCN(hidden_channels=16)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)
criterion = torch.nn.CrossEntropyLoss()

def train():
      model.train()
      optimizer.zero_grad()  # Clear gradients.
      out = model(data.x, data.edge_index)  # Perform a single forward pass.
      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.
      loss.backward()  # Derive gradients.
      optimizer.step()  # Update parameters based on gradients.
      return loss

for epoch in range(1, 201):
    loss = train()
    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')
GCN图神经网络的测试
在训练过程结束后，我们检测GCN图神经网络在测试集上的准确性：

def test():
      model.eval()
      out = model(data.x, data.edge_index)
      pred = out.argmax(dim=1)  # Use the class with highest probability.
      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.
      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.
      return test_acc

test_acc = test()
print(f'Test Accuracy: {test_acc:.4f}')
通过简单地将torch.nn.Linear替换成torch_geometric.nn.GCNConv，我们可以取得81.4%的测试准确率！与前面的仅获得59%的测试准确率的MLP图神经网络相比，GCN图神经网络准确性要高得多。这表明节点的邻接信息在取得更好的准确率方面起着关键作用。

可视化由训练后的GCN图神经网络生成的节点表征
最后我们可视化训练后的GCN图神经网络生成的节点表征，我们会发现“同类节点群聚”的现象更加明显了。这意味着在训练后，GCN图神经网络生成的节点表征质量更高了。

model.eval()

out = model(data.x, data.edge_index)
visualize(out, color=data.y)
image-20210526214436051

图注意力神经网络（GAT）
GAT的定义
图注意神经网络（GAT）来源于论文 Graph Attention Networks。其数学定义为， $$ \mathbf{x}^{\prime}i = \alpha{i,i}\mathbf{\Theta}\mathbf{x}{i} + \sum{j \in \mathcal{N}(i)} \alpha_{i,j}\mathbf{\Theta}\mathbf{x}{j}, $$ 其中注意力系数$\alpha{i,j}$的计算方法为， $$ \alpha_{i,j} = \frac{ \exp\left(\mathrm{LeakyReLU}\left(\mathbf{a}^{\top} [\mathbf{\Theta}\mathbf{x}_i , \Vert , \mathbf{\Theta}\mathbf{x}j] \right)\right)} {\sum{k \in \mathcal{N}(i) \cup { i }} \exp\left(\mathrm{LeakyReLU}\left(\mathbf{a}^{\top} [\mathbf{\Theta}\mathbf{x}_i , \Vert , \mathbf{\Theta}\mathbf{x}_k] \right)\right)}. $$

PyG中GATConv 模块说明
GATConv构造函数接口：

GATConv(in_channels: Union[int, Tuple[int, int]], out_channels: int, heads: int = 1, concat: bool = True, negative_slope: float = 0.2, dropout: float = 0.0, add_self_loops: bool = True, bias: bool = True, **kwargs)
其中：

in_channels ：输入数据维度；
out_channels ：输出数据维度；
heads ：在GATConv使用多少个注意力模型（Number of multi-head-attentions）；
concat ：如为true，不同注意力模型得到的节点表征被拼接到一起（表征维度翻倍），否则对不同注意力模型得到的节点表征求均值；
详细内容请大家参阅GATConv官方文档

GAT图神经网络的构造
将MLP神经网络例子中的torch.nn.Linear替换成torch_geometric.nn.GATConv，来实现GAT图神经网络的构造，如下方代码所示：

import torch
from torch.nn import Linear
import torch.nn.functional as F

from torch_geometric.nn import GATConv

class GAT(torch.nn.Module):
    def __init__(self, hidden_channels):
        super(GAT, self).__init__()
        torch.manual_seed(12345)
        self.conv1 = GATConv(dataset.num_features, hidden_channels)
        self.conv2 = GATConv(hidden_channels, dataset.num_classes)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv2(x, edge_index)
        return x
基于GAT图神经网络的训练和测试，与基于GCN图神经网络的训练和测试相同，此处不再赘述。

结语
在节点表征的学习中，MLP神经网络只考虑了节点自身属性，忽略了节点之间的连接关系，它的结果是最差的；而GCN图神经网络与GAT图神经网络，同时考虑了节点自身信息与周围邻接节点的信息，因此它们的结果都优于MLP神经网络。也就是说，对周围邻接节点的信息的考虑，是图神经网络由于普通深度神经网络的原因。

GCN图神经网络与GAT图神经网络的相同点为：

它们都遵循消息传递范式；
在邻接节点信息变换阶段，它们都对邻接节点做归一化和线性变换；
在邻接节点信息聚合阶段，它们都将变换后的邻接节点信息做求和聚合；
在中心节点信息变换阶段，它们都只是简单返回邻接节点信息聚合阶段的聚合结果。
GCN图神经网络与GAT图神经网络的区别在于采取的归一化方法不同：

前者根据中心节点与邻接节点的度计算归一化系数，后者根据中心节点与邻接节点的相似度计算归一化系数。
前者的归一化方式依赖于图的拓扑结构：不同的节点会有不同的度，同时不同节点的邻接节点的度也不同，于是在一些应用中GCN图神经网络会表现出较差的泛化能力。
后者的归一化方式依赖于中心节点与邻接节点的相似度，相似度是训练得到的，因此不受图的拓扑结构的影响，在不同的任务中都会有较好的泛化表现。
